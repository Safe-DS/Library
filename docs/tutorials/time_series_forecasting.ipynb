{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Time series forecasting\n",
    "\n",
    "This tutorial uses safeds on **US inflation rates data** to predict future inflation with a recurrent neural network. The **US inflation rates data** is a time series. A time series, is a series with frequently measured values. This time series measures the inflation of the US every Month from January 1947 until June 2023.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "1. Load your data into a `Table`. The data is available under `docs/tutorials/data/US_Inflation_rates.csv`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:16.323622900Z",
     "start_time": "2024-05-15T16:07:16.258760500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'safeds'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msafeds\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtabular\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcontainers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Table\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      3\u001B[0m inflation \u001B[38;5;241m=\u001B[39m Table\u001B[38;5;241m.\u001B[39mfrom_csv_file(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/US_Inflation_rates.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'safeds'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from safeds.data.tabular.containers import Table\n",
    "\n",
    "inflation = Table.from_csv_file(\"data/US_Inflation_rates.csv\")\n",
    "# For visualisation purposes we only print out the first 15 rows.\n",
    "inflation.slice_rows(0,15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "This dataset contains two columns: date and value. The date column is right now still a string type with a format like this: \"Year-Month-Day\". We can convert it into a temporal type column like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:16.329132Z",
     "start_time": "2024-05-15T16:07:16.322624400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>value</th></tr><tr><td>date</td><td>f64</td></tr></thead><tbody><tr><td>1947-01-01</td><td>21.48</td></tr><tr><td>1947-02-01</td><td>21.62</td></tr><tr><td>1947-03-01</td><td>22.0</td></tr><tr><td>1947-04-01</td><td>22.0</td></tr><tr><td>1947-05-01</td><td>21.95</td></tr><tr><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1947-11-01</td><td>23.06</td></tr><tr><td>1947-12-01</td><td>23.41</td></tr><tr><td>1948-01-01</td><td>23.68</td></tr><tr><td>1948-02-01</td><td>23.67</td></tr><tr><td>1948-03-01</td><td>23.5</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+------------+----------+\n",
       "| date       |    value |\n",
       "| ---        |      --- |\n",
       "| date       |      f64 |\n",
       "+=======================+\n",
       "| 1947-01-01 | 21.48000 |\n",
       "| 1947-02-01 | 21.62000 |\n",
       "| 1947-03-01 | 22.00000 |\n",
       "| 1947-04-01 | 22.00000 |\n",
       "| 1947-05-01 | 21.95000 |\n",
       "| …          |        … |\n",
       "| 1947-11-01 | 23.06000 |\n",
       "| 1947-12-01 | 23.41000 |\n",
       "| 1948-01-01 | 23.68000 |\n",
       "| 1948-02-01 | 23.67000 |\n",
       "| 1948-03-01 | 23.50000 |\n",
       "+------------+----------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation = inflation.replace_column(\"date\", [inflation.get_column(\"date\").from_str_to_temporal(\"%Y-%m-%d\")])\n",
    "inflation.slice_rows(0,15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As we can see the date column is no longer in quotes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "2. In the second step we prepare the data, to train our neural network. For that we need to normalize our data, because neural networks work better on values between 0 and 1. After that, we split the data into a training and test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:16.332811Z",
     "start_time": "2024-05-15T16:07:16.328131400Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from safeds.data.tabular.transformation import RangeScaler\n",
    "\n",
    "scaler = RangeScaler()\n",
    "trained_scaler, inflation = scaler.fit_and_transform(inflation, [\"value\"])\n",
    "train_set, test_set = inflation.split_rows(percentage_in_first=0.8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "3. To finish our data preparation we mark the datasets as time series, so they can be used in such context for the neural networks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:16.337329700Z",
     "start_time": "2024-05-15T16:07:16.334322200Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "train_time_series = train_set.to_time_series_dataset(target_name=\"value\", time_name=\"date\")\n",
    "test_time_series = test_set.to_time_series_dataset(target_name=\"value\", time_name=\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "If we want to use a neural network to predict what the inflation will be next month, we have to provide it with a relevant chunk of past data that it can learn from. Think of it like looking at a series of snapshots from the past to guess what's going to happen next.\n",
    "\n",
    "Instead of feeding the entire history of inflation data to the neural network all at once, which could be overwhelming and not very helpful, we divide the historical data into smaller, more manageable parts. This technique is known as \"windowing.\"\n",
    "\n",
    "A \"window\" in this context is just a set portion of consecutive data points from the time series. By giving the neural network these windows, it can start to understand how the numbers in the past relate to future values.\n",
    "\n",
    "In our case, we want to look at the last 8 months of inflation data to make a guess about the inflation for the upcoming month. So, we choose a window size of 8. This window will slide across our time series data, providing the neural network with different 8-month segments to learn from.\n",
    "\n",
    "Finally, we tell our neural network that our forecast horizon is 1, meaning that we're interested in predicting the value for just one step ahead—the next month's inflation rate.\n",
    "\n",
    "So, simply put, we set up our neural network to take in 8-month chunks of inflation data to help it make a forecast about the inflation rate for the next month.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:40.603070Z",
     "start_time": "2024-05-15T16:07:16.339625300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ettel\\PycharmProjects\\Library\\venv\\Lib\\site-packages\\torch\\utils\\_device.py:78: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:1424.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from safeds.ml.nn import NeuralNetworkRegressor\n",
    "\n",
    "from safeds.ml.nn.converters import (\n",
    "    InputConversionTimeSeries,\n",
    "    OutputConversionTimeSeries,\n",
    ")\n",
    "from safeds.ml.nn.layers import (\n",
    "    ForwardLayer,\n",
    "    LSTMLayer,\n",
    ")\n",
    "window_size = 8\n",
    "\n",
    "neural_network = NeuralNetworkRegressor(\n",
    "    InputConversionTimeSeries(window_size=window_size, forecast_horizon=1),\n",
    "    [ForwardLayer(input_size=window_size, output_size=256), LSTMLayer(input_size=256, output_size=1)],\n",
    "    OutputConversionTimeSeries(\"predicted\"),\n",
    ")\n",
    "fitted_neural_network = neural_network.fit(train_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "5. Now that we defined and trained our model, we can start making predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:40.686231900Z",
     "start_time": "2024-05-15T16:07:40.604068500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>value</th><th>predicted</th></tr><tr><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2008-12-01</td><td>0.672607</td><td>0.627523</td></tr><tr><td>2009-01-01</td><td>0.674502</td><td>0.630725</td></tr><tr><td>2009-02-01</td><td>0.677236</td><td>0.632174</td></tr><tr><td>2009-03-01</td><td>0.676492</td><td>0.630603</td></tr><tr><td>2009-04-01</td><td>0.67725</td><td>0.628134</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2009-10-01</td><td>0.690708</td><td>0.62319</td></tr><tr><td>2009-11-01</td><td>0.693276</td><td>0.623395</td></tr><tr><td>2009-12-01</td><td>0.693676</td><td>0.624262</td></tr><tr><td>2010-01-01</td><td>0.694175</td><td>0.625218</td></tr><tr><td>2010-02-01</td><td>0.693442</td><td>0.625549</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+------------+---------+-----------+\n",
       "| date       |   value | predicted |\n",
       "| ---        |     --- |       --- |\n",
       "| date       |     f64 |       f64 |\n",
       "+==================================+\n",
       "| 2008-12-01 | 0.67261 |   0.62752 |\n",
       "| 2009-01-01 | 0.67450 |   0.63073 |\n",
       "| 2009-02-01 | 0.67724 |   0.63217 |\n",
       "| 2009-03-01 | 0.67649 |   0.63060 |\n",
       "| 2009-04-01 | 0.67725 |   0.62813 |\n",
       "| …          |       … |         … |\n",
       "| 2009-10-01 | 0.69071 |   0.62319 |\n",
       "| 2009-11-01 | 0.69328 |   0.62339 |\n",
       "| 2009-12-01 | 0.69368 |   0.62426 |\n",
       "| 2010-01-01 | 0.69418 |   0.62522 |\n",
       "| 2010-02-01 | 0.69344 |   0.62555 |\n",
       "+------------+---------+-----------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = fitted_neural_network.predict(\n",
    "    test_time_series\n",
    ")\n",
    "prediction = prediction.to_table()\n",
    "# For visualisation purposes we only print out the first 15 rows.\n",
    "prediction.slice_rows(start=0, length=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "6. Now we only need to inverse our predictions and we can start visualizing them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:40.689879700Z",
     "start_time": "2024-05-15T16:07:40.686231900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (175, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>date</th><th>value</th><th>predicted</th></tr><tr><td>date</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>2008-12-01</td><td>211.398</td><td>0.627523</td></tr><tr><td>2009-01-01</td><td>211.933</td><td>0.630725</td></tr><tr><td>2009-02-01</td><td>212.705</td><td>0.632174</td></tr><tr><td>2009-03-01</td><td>212.495</td><td>0.630603</td></tr><tr><td>2009-04-01</td><td>212.709</td><td>0.628134</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2023-02-01</td><td>301.648</td><td>0.682311</td></tr><tr><td>2023-03-01</td><td>301.808</td><td>0.682405</td></tr><tr><td>2023-04-01</td><td>302.918</td><td>0.682811</td></tr><tr><td>2023-05-01</td><td>303.294</td><td>0.683415</td></tr><tr><td>2023-06-01</td><td>303.841</td><td>0.683646</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "+------------+-----------+-----------+\n",
       "| date       |     value | predicted |\n",
       "| ---        |       --- |       --- |\n",
       "| date       |       f64 |       f64 |\n",
       "+====================================+\n",
       "| 2008-12-01 | 211.39800 |   0.62752 |\n",
       "| 2009-01-01 | 211.93300 |   0.63073 |\n",
       "| 2009-02-01 | 212.70500 |   0.63217 |\n",
       "| 2009-03-01 | 212.49500 |   0.63060 |\n",
       "| 2009-04-01 | 212.70900 |   0.62813 |\n",
       "| …          |         … |         … |\n",
       "| 2023-02-01 | 301.64800 |   0.68231 |\n",
       "| 2023-03-01 | 301.80800 |   0.68241 |\n",
       "| 2023-04-01 | 302.91800 |   0.68281 |\n",
       "| 2023-05-01 | 303.29400 |   0.68342 |\n",
       "| 2023-06-01 | 303.84100 |   0.68365 |\n",
       "+------------+-----------+-----------+"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_scaler._column_names.append(\"predicted\")\n",
    "prediction.inverse_transform_table(fitted_transformer=trained_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-15T16:07:40.692392200Z",
     "start_time": "2024-05-15T16:07:40.690384800Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}